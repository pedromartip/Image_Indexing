{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f8462d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b361c569619c5777091368813c9298fb",
     "grade": false,
     "grade_id": "cell_head_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 11762 Content-Based Image Retrieval\n",
    "## Master's Degree in Intelligent Systems\n",
    "### University of the Balearic Islands\n",
    "\n",
    "---\n",
    "\n",
    "**Before you turn this problem in, please put your full names and DNIs (or NIEs) below, and execute the cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cd0919fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME  = \"Pedro Marti Pico\"\n",
    "DNI   = \"41574536N\"\n",
    "\n",
    "NAME2 = 'Raixa Madueño Mallofré'\n",
    "DNI2  = '49867599B'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9990e233",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e99971bb70936fbf488fd64ed0c1efa",
     "grade": false,
     "grade_id": "cell_head_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. **Justify** all of your answers, **graphically** wherever possible. Remember that this notebook will be considered as a report to the work done during the assignment.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a32b507a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ed34114414f947ea18f0e3a656381d9",
     "grade": false,
     "grade_id": "cell-f6e621d3dd92a9f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Setup code for this assignment\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import scipy.cluster.vq as vq\n",
    "import tqdm\n",
    "import zipfile\n",
    "\n",
    "## Adding parent folder to find other libs\n",
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0,\"..\")\n",
    "\n",
    "import iric_dev_kit.iric_utils.eval_holidays as ev\n",
    "import iric_dev_kit.iric_utils.read_descriptors as rd\n",
    "\n",
    "# Configuring Matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d621778b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f77bb5d66178bad6cd0f36fd224fcb6f",
     "grade": false,
     "grade_id": "cell-3b814276a5ba86db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction\n",
    "In this assignment, you will implement and evaluate different methods for indexing images. As usual during this course, we will use the INRIA Holidays dataset. **Check the Assignment 1 to further information about this dataset.**\n",
    "\n",
    "We also need the provided script to evaluate a CBIR system on this dataset. Remember that the performance is measured computing the **Mean Average Precision** (mAP) over all queries. **Check also the Assignment 1 to remember how to use this script and the different functions it offers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b3c399",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f525c9b743f3383ec8f06c742e58a752",
     "grade": false,
     "grade_id": "cell-da4850e64a976ad8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loading images\n",
    "As we did in Assignment 1, for managing images, we will create four lists:\n",
    "- **`query_names`**: File names of the *query* images\n",
    "- **`query_imgs`**: *Query* images loaded using OpenCV2\n",
    "- **`train_names`**: File names of the *train* (database) images\n",
    "- **`train_imgs`**: *Train* images loaded using OpenCV2\n",
    "\n",
    "In this assignment, we will use the original holidays dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "78adf5f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41c749ebe18a13ff129bf6ea5c39b005",
     "grade": false,
     "grade_id": "cell-a926eab7930fc8b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "991\n"
     ]
    }
   ],
   "source": [
    "# Separating the dataset into query and train images\n",
    "query_names = []\n",
    "query_imgs = []\n",
    "train_names = []\n",
    "train_imgs = []\n",
    "holidays_folder_path = '/Users/pedromarti/Desktop/Máster/IRIC/Practica'\n",
    "with open(f'{holidays_folder_path}/holidays/holidays_images.dat') as f:\n",
    "    for line in f:\n",
    "        imname = line.strip()\n",
    "        imno = int(imname[:-len(\".jpg\")])\n",
    "        img = cv2.imread(f'{holidays_folder_path}/holidays/images/' + imname)\n",
    "        # Resize the images for a faster operation in this assignment\n",
    "        img = cv2.resize(img, None, fx=0.25, fy=0.25, interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "        # Checking if this is a query image\n",
    "        if imno % 100 == 0:\n",
    "            query_names.append(imname)\n",
    "            query_imgs.append(img)\n",
    "        else:\n",
    "            train_names.append(imname)\n",
    "            train_imgs.append(img)\n",
    "\n",
    "print(len(query_names))\n",
    "print(len(train_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7080b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8f2234188c58e21a5ed9b5aa170b06c",
     "grade": false,
     "grade_id": "cell-e0f678da073b3399",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Loading SIFT descriptors\n",
    "In this assignment we will create four additional lists:\n",
    "- **`query_kps`**: A list of lists of keypoints (cv2.KeyPoint) extracted from the *query* images\n",
    "- **`query_desc`**: A list of numpy arrays including, for each set of keypoints, the SIFT descriptors extracted from the *query* images\n",
    "- **`train_kps`**: A list of lists of keypoints (cv2.KeyPoint) extracted from the *train* (database) images\n",
    "- **`train_desc`**: A list of numpy arrays including, for each set of keypoints, the SIFT descriptors extracted from the *train* images\n",
    "\n",
    "Unlike in Assigment 1, now you will be provided with a set of SIFT descriptors for each image, and, therefore, you do not need to create these lists from scratch. First, download the descriptors from [here](https://uibes-my.sharepoint.com/:u:/g/personal/egf350_id_uib_eu/EYIP-UjSucZIsHL6aLNYRCcBDfBAd_42m9fHPuYB3kck4A).\n",
    "\n",
    "> **Unzip this file into the root directory of the development kit, at the same level of the datasets.**\n",
    "\n",
    "Now, a new directory called `siftgeo` should be in your workspace, containing the set of SIFT descriptors for each image of the dataset. These descriptors are stored in binary format and, thus, you are also provided with some tools to load them. To be more precise, you can call the function `load_SIFT_descriptors` to load the descriptors of a list of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f7e7e1c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc1b6e828616c74eecb5bd75ed481bf1",
     "grade": false,
     "grade_id": "cell-b4d6c65646fac5e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "991\n",
      "500\n",
      "991\n",
      "(1000, 128)\n",
      "[[10.  6. 52. ... 15.  4.  0.]\n",
      " [16. 50. 12. ... 15.  4.  0.]\n",
      " [10. 11. 58. ...  7.  4.  4.]\n",
      " ...\n",
      " [27. 15.  0. ... 16.  8. 12.]\n",
      " [51. 47. 14. ... 35. 26.  0.]\n",
      " [ 2. 37. 25. ... 47. 13.  8.]]\n"
     ]
    }
   ],
   "source": [
    "# Loading descriptors\n",
    "query_kps, query_desc = rd.load_SIFT_descriptors(query_names, max_desc=1000)\n",
    "train_kps, train_desc = rd.load_SIFT_descriptors(train_names, max_desc=1000)\n",
    "\n",
    "# Some prints\n",
    "print(len(query_kps))\n",
    "print(len(train_kps))\n",
    "print(len(query_desc))\n",
    "print(len(train_desc))\n",
    "print(query_desc[0].shape)\n",
    "print(query_desc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f8d0c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "def82a2846a9805038575d7a32f876d1",
     "grade": false,
     "grade_id": "cell-ab2d437e9c4904da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For development purposes, we use the parameter `max_desc` to load a maximum number (1000) of the descriptors. This will speed up the execution of the rest of the notebook, while the decrease in performance will be minimum.\n",
    "\n",
    "> **Some images do not have keypoints/descriptors. Take this into account when you develop your solution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2aeee4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60adae6f4efbeab4f703dbd5766b886a",
     "grade": false,
     "grade_id": "cell-d1426301b6919ea6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## $k$-d trees and LSH \n",
    "Let's start coding. At this section, you will develop a retrieval system using $k$-d trees and Locality Sensitive Hashing (LSH). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ec641",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f777b4f2f29da5a3b28c0c26ca4e9859",
     "grade": false,
     "grade_id": "cell-06801f1c07fb6919",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General framework\n",
    "As we did in the first assignment, you first will develop some utilities to simplify your work. Write a function called `search_image` to search an image in a generic index (database). You should search each descriptor of the given query image and obtain its two closest SIFT descriptors in the database. Next, the initial set of matches should be filtered using the **NNDR criterion (use 0.8 as ratio)**, as you did in the previous assignment. For each database image, its final score with regard to this query image will be the **number of correct matches** with this image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d9560c34",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83f21825a10b2eff1d2829d308a0fd11",
     "grade": false,
     "grade_id": "cell-0bdc1eecfec1c973",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def search_image(descs, index, id_to_name):\n",
    "    \"\"\"\n",
    "    Search an image in the index\n",
    "    \n",
    "    - descs: A numpy array. This is the set descriptors extracted from the query image\n",
    "    - index: OpenCV FLANN index to search for descriptors.\n",
    "    - id_to_name: An associative list to link every image index to its real name\n",
    "        e.g. id_to_name[0] = '100001.jpg', id_to_name[1] = '100002.jpg'\n",
    "  \n",
    "    RETURN: \n",
    "    - An ordered list of similar images, e.g.: ['100101.jpg', '100202.jpg', ...]\n",
    "    \"\"\"\n",
    "    descs = np.float32(descs)\n",
    "    # Search for the closest descriptors in the index\n",
    "    matches = index.knnMatch(descs, k=2)  # Get two nearest neighbors for each query descriptor\n",
    "    \n",
    "    # Filter matches using NNDR criterion\n",
    "    good_matches = []\n",
    "    for match in matches:\n",
    "        if match[0].distance > match[1].distance * 0.8:  # Ratio test\n",
    "            #print(f'Estoy metiendo {id_to_name[match[0].imgIdx]}')\n",
    "            good_matches.append(id_to_name[match[0].imgIdx])\n",
    "\n",
    "    # Count the number of correct matches for each database image\n",
    "    image_scores = {}\n",
    "    for match in good_matches:\n",
    "        if match in image_scores:\n",
    "            image_scores[match] += 1\n",
    "        else:\n",
    "            image_scores[match] = 1\n",
    "\n",
    "    # Sort the images by their scores in descending order\n",
    "    sorted_images = sorted(image_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Extract only the image names from the sorted list\n",
    "    similar_images = [image[0] for image in sorted_images]\n",
    "\n",
    "    return similar_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470e6a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9645cb4e0f90d6437de5fa72c21ef651",
     "grade": false,
     "grade_id": "cell-349a4f0ebb8e378b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, write a function called `compute_mAP`. Given a list of query images and a trained index, this function should return a Python dictionary with the ordered results for each query along with the computed mAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a13485b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mAP(query_names, query_desc, index, id_to_name):\n",
    "    \"\"\"\n",
    "    Perform a search for a list of query images against the database.\n",
    "    \n",
    "    - query_names: An ordered list with the names of the query images\n",
    "    - query_desc: A list containing numpy arrays of size (ndesc_for_this_image, 128)\n",
    "                  Each numpy array i corresponds to the descriptors found at image i\n",
    "    - index: FLANN index\n",
    "    - id_to_name: An associative array to link every image index to its real name\n",
    "                  e.g. id_to_name[0] = '100001.jpg', id_to_name[1] = '100002.jpg'\n",
    "  \n",
    "    RETURN: \n",
    "    - total_results: A dictionary containing, for each query image, an sorted list of the database images\n",
    "    - m_ap: Mean Average Precision averaged over all queries\n",
    "    \"\"\"\n",
    "    total_results = {}\n",
    "    for i, descs in enumerate(query_desc):\n",
    "        #For each descriptor, it calls the search_image to find the closest matches in the FLANN index.\n",
    "        results = search_image(descs, index, id_to_name)\n",
    "        total_results[query_names[i]] = results\n",
    "\n",
    "    m_ap = ev.compute_mAP(total_results, f'{holidays_folder_path}/holidays/holidays_images.dat')\n",
    "    \n",
    "    return total_results, m_ap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7782f8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3eda381e7ffcc78a7ec1e7c916eab2a2",
     "grade": false,
     "grade_id": "cell-41b189c4ea538e00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### $k$-d Trees\n",
    "In this section you will use a set of randomized $k$-d trees to index the database of images. Write a function called `build_db_kdtrees` to build a set of randomized $k$-d trees given a set of descriptors:\n",
    "\n",
    "> **Useful links**: [cv2.FlannBasedMatcher](https://docs.opencv.org/4.5.5/dc/de2/classcv_1_1FlannBasedMatcher.html), [Possible algorithms to create an index](https://docs.opencv.org/4.5.5/db/d18/classcv_1_1flann_1_1GenericIndex.html#a8fff14185f9f3d2f2311b528f65b146c), [Algorithms IDs](https://github.com/opencv/opencv/blob/master/modules/flann/include/opencv2/flann/defines.h#L70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3586111e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a4f13ccc15c7eb033518fc08fabcfff",
     "grade": false,
     "grade_id": "cell-19e04b97f8d87a86",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def build_db_kdtrees(descs, ntrees = 4):\n",
    "    \"\"\"\n",
    "    Build a set of randomized k-d trees.\n",
    "    \n",
    "    - descs: A list of length len(img_names) where each element is a numpy array \n",
    "        of size (ndesc_for_this_image, 128). Each numpy array i corresponds \n",
    "        to the descriptors found on image i\n",
    "    - ntrees: Number of trees to train\n",
    "  \n",
    "    RETURN: \n",
    "    - index: Trained FLANN index\n",
    "    \"\"\"  \n",
    "\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=ntrees)\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    flann.add(descs)\n",
    "    flann.train()\n",
    "    \n",
    "    return flann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2fe39d9d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb2220563691ccf61e3d342d9b287da7",
     "grade": true,
     "grade_id": "cell-803ccdc307b881ec",
     "locked": true,
     "points": 0.35,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Simple example of DB construction\n",
    "index = build_db_kdtrees(train_desc[0:2])\n",
    "print(len(index.getTrainDescriptors()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8598581a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78413f286a0c5bc8130c2fc5786a1872",
     "grade": true,
     "grade_id": "cell-207a3f0134254933",
     "locked": true,
     "points": 0.35,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100001.jpg', '100002.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Search an image in the index\n",
    "img_res = search_image(query_desc[0], index, train_names[0:2])\n",
    "print(img_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9d3780a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of computing mAP\n",
    "results, mAP = compute_mAP(query_names, query_desc, index, train_names[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7b7bdece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012\n"
     ]
    }
   ],
   "source": [
    "print(mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0c32c81c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f8eea34eed5f81d059b93a46ecd69a8",
     "grade": true,
     "grade_id": "cell-bf632685cb412e33",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100002.jpg', '100002.jpg', '100001.jpg', '100002.jpg', '100001.jpg', '100002.jpg', '100001.jpg', '100002.jpg', '100002.jpg', '100002.jpg', '100001.jpg', '100002.jpg']\n",
      "['100002.jpg', '100001.jpg', '100002.jpg', '100001.jpg', '100002.jpg', '100001.jpg', '100001.jpg', '100002.jpg', '100002.jpg', '100001.jpg', '100001.jpg', '100002.jpg', '100002.jpg', '100001.jpg', '100001.jpg', '100002.jpg', '100001.jpg', '100002.jpg', '100001.jpg', '100001.jpg', '100002.jpg', '100001.jpg', '100002.jpg', '100002.jpg', '100001.jpg', '100001.jpg', '100001.jpg', '100001.jpg', '100001.jpg', '100001.jpg', '100001.jpg', '100002.jpg', '100001.jpg', '100002.jpg', '100002.jpg', '100002.jpg', '100001.jpg', '100001.jpg', '100002.jpg', '100001.jpg', '100001.jpg', '100002.jpg', '100001.jpg', '100002.jpg', '100002.jpg']\n",
      "0.012\n"
     ]
    }
   ],
   "source": [
    "# Example of computing mAP\n",
    "results, mAP = compute_mAP(query_names, query_desc, index, train_names[0:2])\n",
    "print(results['100000.jpg'])\n",
    "print(results['100100.jpg'])\n",
    "print(mAP) # This should be 0 now, since there is only two images in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec669537",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88ad41437443c287f925e3cf262365ad",
     "grade": false,
     "grade_id": "cell-2ed91024e8f67fdf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q1**: Using functions developed so far, in the following cell compute the resulting **mAP** of the system **using 4 trees**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d3d0cfe3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "682488215de47970cc34d71265a92481",
     "grade": false,
     "grade_id": "cell-04f414377f3437e6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 trees\n",
      "mAP: 0.01421\n",
      "Total time: 3.94802 seconds\n"
     ]
    }
   ],
   "source": [
    "# Fill this variable with the resulting mAP\n",
    "mAP_kdtree = 0.0\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.perf_counter()\n",
    "index = build_db_kdtrees(train_desc[0:4])\n",
    "# Search an image in the index\n",
    "img_res = search_image(query_desc[0], index, train_names[0:4])\n",
    "# Fill this variable with the resulting mAP\n",
    "results, mAP_kdtree = compute_mAP(query_names, query_desc, index, train_names[0:4])\n",
    "# Calc of total time    \n",
    "total_time = time.perf_counter() - start_time\n",
    "print('4 trees')\n",
    "print('mAP: %.5f' % mAP_kdtree)\n",
    "print(f\"Total time: {total_time:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f3ef5289",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b84112f2224a789def8dcb4f067f9314",
     "grade": true,
     "grade_id": "cell-26ff0e22e3398306",
     "locked": true,
     "points": 0.3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 trees\n",
      "mAP: 0.01637\n",
      "Total time: 3.83062 seconds\n"
     ]
    }
   ],
   "source": [
    "# Record the start time\n",
    "start_time = time.perf_counter()\n",
    "index = build_db_kdtrees(train_desc[0:4])\n",
    "# Search an image in the index\n",
    "img_res = search_image(query_desc[0], index, train_names[0:6])\n",
    "# Fill this variable with the resulting mAP\n",
    "results, mAP_kdtree = compute_mAP(query_names, query_desc, index, train_names[0:6])\n",
    "# Calc of total time    \n",
    "total_time = time.perf_counter() - start_time\n",
    "print('6 trees')\n",
    "print('mAP: %.5f' % mAP_kdtree)\n",
    "print(f\"Total time: {total_time:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "45f29fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trees\n",
      "mAP: 0.01190\n",
      "Total time: 15.88285 seconds\n"
     ]
    }
   ],
   "source": [
    "# Record the start time\n",
    "start_time = time.perf_counter()\n",
    "index = build_db_kdtrees(train_desc)\n",
    "# Search an image in the index\n",
    "img_res = search_image(query_desc[0], index, train_names)\n",
    "# Fill this variable with the resulting mAP\n",
    "results, mAP_kdtree = compute_mAP(query_names, query_desc, index, train_names)\n",
    "# Calc of total time    \n",
    "total_time = time.perf_counter() - start_time\n",
    "print('Total trees')\n",
    "print('mAP: %.5f' % mAP_kdtree)\n",
    "print(f\"Total time: {total_time:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bae631",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8837b491f312c23d720b289d446df108",
     "grade": false,
     "grade_id": "cell-1beea12d1f8191d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q2**: Are the results stable? Do you obtain always the same mAP? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72827768",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a083d74d09c0478de8347d42afc480e2",
     "grade": false,
     "grade_id": "cell-ec07385de7cc53f8",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87432f8f",
   "metadata": {},
   "source": [
    "\n",
    "## **Response:** \n",
    "\n",
    "### The results show variability in the mAP, with different mAP values obtained when changing the number of trees used in the indexing process. Specifically, the mAP increases from 0.01421 with four trees to 0.01637 with six trees, then decreases to 0.01190 when all trees are used. \n",
    "\n",
    "### This variation can be attributed to the random construction of k-d trees, where different splits in the data can lead to slightly different tree structures and, consequently, affect the nearest neighbor search results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baed384",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1c86d138c2c669b41e3a51679ce66bc",
     "grade": false,
     "grade_id": "cell-841e3c52c9507dd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q3:** Analyze the effect of changing the number of trees in terms of mAP and average response time. Some plots here can be useful to justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57caf1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5db66b397a32190212db1ae492721778",
     "grade": false,
     "grade_id": "cell-d936cbc9cbbff824",
     "locked": true,
     "points": 0.4,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52633ad1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c4200b732e230d6a8a6b768558cdfd9",
     "grade": false,
     "grade_id": "cell-f1f7ebd50bedb10b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Locality Sensitive Hashing (LSH)\n",
    "In this section, you will use LSH to index the database of images. The LSH implementation included in OpenCV uses **bit sampling** for **Hamming distance** as a hash function and, therefore, binary descriptors must be used. Hence, SIFT descriptors are not valid and we need to describe the images, but using, for instance, ORB.\n",
    "\n",
    "In the following cell, write the code required to generate **roughly 1500 keypoints / descriptors** using ORB for each query / train image:\n",
    "\n",
    "> **Useful links**: [cv2.ORB_create](https://docs.opencv.org/4.5.4/db/d95/classcv_1_1ORB.html#aeff0cbe668659b7ca14bb85ff1c4073b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4b1223cb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc9a6073046a70410fc58fcb05637321",
     "grade": false,
     "grade_id": "cell-062e499099d47f25",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "query_kps_orb  = []\n",
    "query_desc_orb = []\n",
    "train_kps_orb  = []\n",
    "train_desc_orb = []\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Creation of an ORB detector with 1500 keypoints and a scaling pyramid factor of 1.2\n",
    "orb = cv2.ORB_create(nfeatures=1500, scaleFactor=1.2)\n",
    "\n",
    "# Loop over all images in the query dataset.\n",
    "for img in query_imgs:\n",
    "    # Detect keypoints and compute the ORB descriptors for the image\n",
    "    kps, desc = orb.detectAndCompute(img, None)\n",
    "    \n",
    "    # Append the detected keypoints and their corresponding descriptors to their respective lists\n",
    "    query_kps_orb.append(kps)\n",
    "    query_desc_orb.append(desc)\n",
    "\n",
    "# Repeat the process for all images in the training dataset.\n",
    "for img in train_imgs:\n",
    "    kps, desc = orb.detectAndCompute(img, None)\n",
    "    train_kps_orb.append(kps)\n",
    "    train_desc_orb.append(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "03aa9edf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9a38f6232680ae68df6075ea3ebc06f",
     "grade": true,
     "grade_id": "cell-6d11da6cb5de46b2",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "(1500, 32)\n",
      "[[ 28   9  47 ...  59 117 234]\n",
      " [188 207 104 ... 137  94 168]\n",
      " [124  43 176 ... 111 222   3]\n",
      " ...\n",
      " [ 94 164 195 ...  68 167  82]\n",
      " [162  43 172 ...  93  90 207]\n",
      " [  6  10 190 ... 105  37  67]]\n"
     ]
    }
   ],
   "source": [
    "# Show some data\n",
    "print(len(query_kps_orb[0]))  # Number of keypoints detected in the first query image\n",
    "print(query_desc_orb[0].shape)  # Shape of the descriptor array for the first query image\n",
    "print(query_desc_orb[0])  # Descriptor array for the first query image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3362cc8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a9880eb8c1c99547f3fe1539255e4d6",
     "grade": false,
     "grade_id": "cell-a600dc9ab1f5c001",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, write a function called `build_db_lsh` to build a **standard** (*no multi-probe*) LSH index from a set of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7f4e0e3e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01a750d8c65eeb552ecc7df3d46c5dc4",
     "grade": false,
     "grade_id": "cell-93ee6119edf6b51c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def build_db_lsh(descs, tables = 6, hash_size = 12):\n",
    "    \"\"\"\n",
    "    Index a set of images using LSH.    \n",
    "    \n",
    "    - descs: A list containing numpy arrays of size (~1500, 32). Each numpy array\n",
    "        i corresponds to the ORB descriptors found at image i.\n",
    "    - tables: Number of hash tables to create.\n",
    "    - hash_size: Hash length in bits.\n",
    "  \n",
    "    RETURN: \n",
    "    - index: The trained LSH index.\n",
    "    \"\"\"  \n",
    "  \n",
    "    # Index a set of images using LSH\n",
    "    FLANN_INDEX_LSH = 6\n",
    "    index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=tables, key_size=hash_size, multi_probe_level=1)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, {})\n",
    "    flann.add(descs)\n",
    "    flann.train()\n",
    "    return flann # flann = index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "80ccfabe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fdc504017e8d06899e084c165d74520",
     "grade": true,
     "grade_id": "cell-4cd31f9613416c8c",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Simple example of DB construction\n",
    "index = build_db_lsh(train_desc_orb[0:2])\n",
    "print(len(index.getTrainDescriptors()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e09cc8",
   "metadata": {},
   "source": [
    "## Analysing the effect of varying the number of hash tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a02f02dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/6tyw6rld1nn68w3tjknkqmkw0000gn/T/ipykernel_69433/737290071.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  index = build_db_lsh(np.array(train_desc_orb), tables=tables)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m index \u001b[38;5;241m=\u001b[39m build_db_lsh(np\u001b[38;5;241m.\u001b[39marray(train_desc_orb), tables\u001b[38;5;241m=\u001b[39mtables)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Assume 'compute_mAP' function is available to calculate mAP\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m results, mAP \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_mAP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_desc_orb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     12\u001b[0m map_scores\u001b[38;5;241m.\u001b[39mappend(mAP)\n",
      "Cell \u001b[0;32mIn[122], line 28\u001b[0m, in \u001b[0;36mcompute_mAP\u001b[0;34m(query_names, query_desc, index, id_to_name)\u001b[0m\n\u001b[1;32m     26\u001b[0m query_name \u001b[38;5;241m=\u001b[39m query_names[i]\n\u001b[1;32m     27\u001b[0m query \u001b[38;5;241m=\u001b[39m query_desc[i]\n\u001b[0;32m---> 28\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknnMatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Extract the indices from the DMatch objects\u001b[39;00m\n\u001b[1;32m     30\u001b[0m flat_indices \u001b[38;5;241m=\u001b[39m [match\u001b[38;5;241m.\u001b[39mtrainIdx \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m matches \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m sublist]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "map_scores, response_times = [], []\n",
    "hash_tables = [2, 4, 6, 8, 10, 12]\n",
    "\n",
    "# Iteration over each hash table\n",
    "for tables in hash_tables:\n",
    "    start_time = time.time() # Record the start time\n",
    "    index = build_db_lsh(np.array(train_desc_orb), tables=tables) # Bulding the LSH index\n",
    "    results, mAP = compute_mAP(query_names, query_desc_orb, index, train_names)\n",
    "    end_time = time.time() # End record time\n",
    "    \n",
    "    map_scores.append(mAP)\n",
    "    response_times.append(end_time - start_time)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hash_tables, map_scores, marker='o')\n",
    "plt.title('mAP vs. Number of Hash Tables')\n",
    "plt.xlabel('Number of Hash Tables')\n",
    "plt.ylabel('mAP')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hash_tables, response_times, marker='o')\n",
    "plt.title('Response Time vs. Number of Hash Tables')\n",
    "plt.xlabel('Number of Hash Tables')\n",
    "plt.ylabel('Response Time (seconds)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544ed8d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38d285da40073176866dd77553724748",
     "grade": false,
     "grade_id": "cell-a1da1133b9232fd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q4**: In the following cell compute the resulting **mAP** of the system **using 6 tables and a hash size of 12**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ebcfb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f3191083982b55431eff3415f61b7f1",
     "grade": false,
     "grade_id": "cell-f87580b24fd1f890",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Fill this variable with the resulting mAP\n",
    "mAP_lsh = 0.0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9716be7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f17a5c7ff24433ee72fc57309464e1d",
     "grade": true,
     "grade_id": "cell-ec858b0d23c14805",
     "locked": true,
     "points": 0.3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('mAP: %.5f' % mAP_lsh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e599bd3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "366c9df3aeae12173192aac1056ff733",
     "grade": false,
     "grade_id": "cell-d8075ffe941e29c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q5**: Are the results stable? Do you obtain always the same mAP? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71126dfa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c85322c4a8c34cc55f2f7ad98540d84b",
     "grade": false,
     "grade_id": "cell-edcdac402707a587",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64381fca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7f9251c9c2fb58a5c8da91e18ff247f",
     "grade": false,
     "grade_id": "cell-cc45a7e11a9d7418",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q6**: Analyze the effect of changing the number of tables / hash size in terms of mAP and average response time. Some plots here can be useful to justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978b7c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c93526152466646fa030e2f834b3a1d",
     "grade": false,
     "grade_id": "cell-619d74db24e88fa1",
     "locked": true,
     "points": 0.4,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74726440",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "782f69599ceab03a607af447630838a5",
     "grade": false,
     "grade_id": "cell-188915bcd830f95d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q7:** Despite the different descriptors used, compare the performance of the randomized k-d trees and LSH approaches from different points of view (accuracy, training times, querying times, ...). Some plots can be useful here to justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf65981",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a5c50934954a56f23bc0f37e08b7966c",
     "grade": false,
     "grade_id": "cell-4b9be38f6bd33f20",
     "locked": true,
     "points": 0.4,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d89bb5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14f9f77fddd83546aa0e96298ad3d679",
     "grade": false,
     "grade_id": "cell-6c6989014e168fd5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Bag-of-Words\n",
    "In this section, you will implement the Bag-of-Words (BoW) model for image retrieval. Additionally, you will also implement the TF-IDF scoring scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b174ede",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee73dde5e5d6b1485ea69860ed75d5fe",
     "grade": false,
     "grade_id": "cell-7947a0a3afccdc15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Download visual dictionaries\n",
    "To use a BoW model, first we need a visual vocabulary. The authors of the INRIA Holidays dataset provide some visual vocabularies, trained using a clustering method (e.g. $k$-means) in a different dataset (Flickr60K).\n",
    "\n",
    "First, download these vocabularies from [here](https://uibes-my.sharepoint.com/:u:/g/personal/egf350_id_uib_eu/EfPtO8E2-vZFj6Bs3U3MjpgBNtfT0Xwq7jKZSmgi1qLriQ).\n",
    "\n",
    "> **Unzip this file into the root directory of the development kit, at the same level of the datasets.**\n",
    "\n",
    "A folder named `clust` is now available in your workspace, containing visual vocabularies of 100, 200, 500, 1K, 2K, 5K, 10K, 20K, 50K, 100K and 200K visual words. Again, these are binary files, and therefore we provide you with functions to load and index them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26fefdc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "260872183e8d586227feb2e0dd63b319",
     "grade": false,
     "grade_id": "cell-99af7beaa1c3d539",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "voc = rd.load_visual_vocab(\"../clust/clust_flickr60_k200.fvecs\", ntrees=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d05851",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea4b06e011018dbe3d7bf80de465099f",
     "grade": false,
     "grade_id": "cell-80d1363425120021",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "With this function, the corresponding vocabulary is read. Additionally, a FLANN index structure based on kd-trees is built and returned using the centroids. This is to allow a fast access when searching for the closest visual words in the vocabulary. More precisely, in this example, 4 trees are constructed using the vocabulary of 200 centroids. Now, given a query descriptor(s), you can use `match` or `knnMatch` methods as usual to search for the closest (approximate) visual word(s) in the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ccb141",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "164ce1676b0e0fda5d17a0c62fc7da16",
     "grade": false,
     "grade_id": "cell-fe94465177ae4be8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### BoW and Inverted File\n",
    "Now, write a class called `BoW` to manage the indexing procedure. This class should make use, in addition to the visual vocabulary, an inverted file to compute similarity scores between images. Apart from the class constructor, write three methods: `build_db`, `search_image` and `compute_mAP` as detailed in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ae103",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a9a5c8c0be2e00e9d152352d3ecdfea",
     "grade": false,
     "grade_id": "cell-aeb911c85fbfcee0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BoW:\n",
    "    \"\"\"\n",
    "    Class to implement the BoW model + Inverted File.\n",
    "    \"\"\"\n",
    "  \n",
    "    def __init__(self, vocab_file):\n",
    "        \"\"\"\n",
    "        Class constructor. It loads the vocabulary and initializes other stuff\n",
    "        required for the CBIR system, such as the inverted file structure.\n",
    "        \"\"\"\n",
    "        self.vocab = rd.load_visual_vocab(vocab_file)\n",
    "        self.nwords = self.vocab.getTrainDescriptors()[0].shape[0]\n",
    "        self.train_names = []\n",
    "        self.inv_list = {word_id: {} for word_id in range(self.nwords)}\n",
    "\n",
    "    def build_db(self, img_names, img_descs):\n",
    "        \"\"\"\n",
    "        Build an index from a set of images. Essentially, for each image, you should\n",
    "        search its descriptors in the index in order to find the closest visual words\n",
    "        and fill the inverted file structure consequently.\n",
    "    \n",
    "        - img_names: An ordered list with the names of the train images\n",
    "        - img_descs: A list containing numpy arrays. Each numpy array i corresponds \n",
    "          to the descriptors found at image i\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def search_image(self, descs):\n",
    "        \"\"\"\n",
    "        Search an image in the index. You can freely filter the images according to a \n",
    "          specific criteria. For instance, image that have at least, one vote.\n",
    "      \n",
    "        - descs: A numpy array. It is the set descriptors extracted from the query image.\n",
    "    \n",
    "        RETURN:\n",
    "        - An ordered list of similar images, e.g.: ['100101.jpg', '100202.jpg', ...]\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def compute_mAP(self, query_names, query_descs):\n",
    "        \"\"\"\n",
    "        Perform a search for a list of query images against the database and evaluates\n",
    "        the performance of the system.\n",
    "        \n",
    "        - query_names: An ordered list with the names of query images\n",
    "        - query_descs: A list containing numpy arrays of size (ndesc_for_this_image, 128). \n",
    "              Each numpy array i corresponds to the descriptors found at image i.\n",
    "\n",
    "        RETURN:\n",
    "        - total_results: A dictionary containing, for each query image, an ordered list of the retrieved images.\n",
    "        - m_ap: Mean Average Precision averaged over all queries.\n",
    "        \"\"\"\n",
    "        total_results = {}\n",
    "        m_ap = 0.0\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        return total_results, m_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd007f2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cdbbd209adde95163e67301a02db290",
     "grade": true,
     "grade_id": "cell-f6be571325c7ade3",
     "locked": true,
     "points": 0.3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Example of use\n",
    "index = BoW('../clust/clust_flickr60_k200.fvecs')\n",
    "index.build_db(train_names[0:2], train_desc[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12b2730",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "444e59917aacd3108acb0d640bf30462",
     "grade": true,
     "grade_id": "cell-df1c6aaa914fbec3",
     "locked": true,
     "points": 0.4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "res = index.search_image(query_desc[0])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1661e449",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b31bdb24f4274ae7866295e1a76c17c1",
     "grade": true,
     "grade_id": "cell-3cab945e87903d31",
     "locked": true,
     "points": 0.3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "results, mAP = index.compute_mAP(query_names, query_desc)\n",
    "print(results)\n",
    "print(mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5046a9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "763e74c102202322912c057bc8327544",
     "grade": false,
     "grade_id": "cell-fdf71f42f5f298ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q8**: In the following cell compute the resulting mAP of the system **using the vocabularies of 200, 2K, 20K and 200K visual words**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8901aab",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70f60d56a1270671470b02ff879a740d",
     "grade": false,
     "grade_id": "cell-4176faf951e0cc65",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Fill these variables with the resulting mAP\n",
    "mAP_200  = 0.0\n",
    "mAP_2K   = 0.0\n",
    "mAP_20K  = 0.0\n",
    "mAP_200K = 0.0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ed565",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcea21868d957c7425e74ae4a5032825",
     "grade": true,
     "grade_id": "cell-f4374afc6ecce161",
     "locked": true,
     "points": 0.3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('mAP 200: %.5f' % mAP_200)\n",
    "print('mAP 2K: %.5f' % mAP_2K)\n",
    "print('mAP 20K: %.5f' % mAP_20K)\n",
    "print('mAP 200K: %.5f' % mAP_200K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e818e7c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07f57bc9d9bd78d99b403602f8a90e44",
     "grade": false,
     "grade_id": "cell-e5a519c51fa0069b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q9**: Compare the performances obtained on each case. Is a larger vocabulary size always better? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6015870",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "564ebe7c40dcffe1c50dfe735098e350",
     "grade": false,
     "grade_id": "cell-9429db3024616a16",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b582757",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b81f882f6c67715a70baf6a6e3e38d1",
     "grade": false,
     "grade_id": "cell-971d658462e12e6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q10**: Analyze the effect of the vocabulary size in terms of mAP and average response time (train and query times). Are these times constant for each vocabulary? Some plots here can be useful to justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7695e01",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "193e620c3bf540dd97e40ee42b830638",
     "grade": false,
     "grade_id": "cell-1e355e0c5cb28de0",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98f5416",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb7b5be6b81db0380ab35f49a6552a21",
     "grade": false,
     "grade_id": "cell-219866d30da6310f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q11**: Do the results obtained depend on the set of images used to generate the vocabulary? How can we improve the retrieval performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7345924",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e5d90633e2fc5b72aa613279c228f6c",
     "grade": false,
     "grade_id": "cell-96569c702b5b7198",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28efbead",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe4a6d363c03ec519f228f1c2fcb8a22",
     "grade": false,
     "grade_id": "cell-4795f460941688a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### TF-IDF\n",
    "As a final task of this assignment, let's implement the TF-IDF scoring scheme. Modify the `BoW` class you wrote before to include the TF-IDF weighting scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cafcc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a5bbebd21d49ef285373e0436c7e36c",
     "grade": false,
     "grade_id": "cell-a65f0d83a4e6326d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BoW_TFIDF:\n",
    "    \"\"\"\n",
    "    Class to implement the BoW model + Inverted File + TF-IDF Scoring scheme\n",
    "    \"\"\"\n",
    "  \n",
    "    def __init__(self, vocab_file):\n",
    "        \"\"\"\n",
    "        Class constructor. It loads the vocabulary and initializes other stuff\n",
    "        required for the CBIR system, such as the inverted file structure.\n",
    "        \"\"\"\n",
    "        self.vocab = rd.load_visual_vocab(vocab_file)\n",
    "        self.nwords = self.vocab.getTrainDescriptors()[0].shape[0]\n",
    "        self.train_names = []\n",
    "        self.inv_list = {word_id: {} for word_id in range(self.nwords)}        \n",
    "        self.tfidf = {}\n",
    "\n",
    "    def build_db(self, img_names, img_descs):\n",
    "        \"\"\"\n",
    "        Build an index from a set of images. Essentially, for each image, you should\n",
    "        search its descriptors in the index in order to find the closest visual words\n",
    "        and fill the inverted file structure consequently. Additionally, TF and IDF terms\n",
    "        should be computed here.\n",
    "    \n",
    "        - img_names: An ordered list with the names of the train images\n",
    "        - img_descs: A list containing numpy arrays. Each numpy array i corresponds \n",
    "          to the descriptors found at image i\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def search_image(self, descs):\n",
    "        \"\"\"\n",
    "        Search an image in the index. Use the TF-IDF here when scoring the images.\n",
    "      \n",
    "        - descs: A numpy array. It is the set descriptors extracted from the query image.\n",
    "    \n",
    "        RETURN:\n",
    "        - An ordered list of similar images, e.g.: ['100101.jpg', '100202.jpg', ...]\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def compute_mAP(self, query_names, query_descs):\n",
    "        \"\"\"\n",
    "        Perform a search for a list of query images against the database and evaluates\n",
    "        the performance of the system.\n",
    "        \n",
    "        - query_names: An ordered list with the names of query images\n",
    "        - query_descs: A list containing numpy arrays of size (ndesc_for_this_image, 128). \n",
    "              Each numpy array i corresponds to the descriptors found at image i.\n",
    "\n",
    "        RETURN:\n",
    "        - total_results: A dictionary containing, for each query image, an ordered list of the retrieved images.\n",
    "        - m_ap: Mean Average Precision averaged over all queries.\n",
    "        \"\"\"\n",
    "        total_results = {}\n",
    "        m_ap = 0.0\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        return total_results, m_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bb6a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a7f9e72db766bbb46a9351d79c32153",
     "grade": true,
     "grade_id": "cell-5852069de28f4013",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Example of use\n",
    "index = BoW_TFIDF('../clust/clust_flickr60_k200.fvecs')\n",
    "index.build_db(train_names[0:2], train_desc[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de5068e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0becf97cffc51eee9453ec7f73d0b7bf",
     "grade": true,
     "grade_id": "cell-96c066a07526d05c",
     "locked": true,
     "points": 0.45,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "res = index.search_image(query_desc[0])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a554f0a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82c28d6c0fdd0e7ad5f379588c605055",
     "grade": false,
     "grade_id": "cell-575949824f2de049",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q12**: In the following cell compute the resulting mAP of the system **using the vocabularies of 200, 2K, 20K and 200K visual words**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307706a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c95346b797b2cca41bcecdc3662a524",
     "grade": false,
     "grade_id": "cell-0d04839ddb813322",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Fill these variables with the resulting mAP\n",
    "mAP_200  = 0.0\n",
    "mAP_2K   = 0.0\n",
    "mAP_20K  = 0.0\n",
    "mAP_200K = 0.0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4761f6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6875afc6dfca2a616f133288c78f80b8",
     "grade": true,
     "grade_id": "cell-376a7cc3cc44f953",
     "locked": true,
     "points": 0.3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('mAP 200: %.5f' % mAP_200)\n",
    "print('mAP 2K: %.5f' % mAP_2K)\n",
    "print('mAP 20K: %.5f' % mAP_20K)\n",
    "print('mAP 200K: %.5f' % mAP_200K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa3cf87",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58e36b7d12f7a1862ee69a275c488e78",
     "grade": false,
     "grade_id": "cell-72b92aeae5e2af5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q13:** Compare the performances obtained on each case. Is a larger vocabulary size always better? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6852c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3f86e368c5ab58b8438a3e3f04f4ecb",
     "grade": false,
     "grade_id": "cell-cb30e6754f8a5982",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752ac143",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1323fe25eb88898f8692a84bce80fd7d",
     "grade": false,
     "grade_id": "cell-48a4fa20de0d9cb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q14**: Analyze the effect of the vocabulary size in terms of mAP and average response time (train and query times). Are these times constant for each vocabulary? Some plots here can be useful to justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07db06d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "893995c02d8723df87a01fb6358c0444",
     "grade": false,
     "grade_id": "cell-2ee84889d64d2b77",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc83c87",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47620cd7566940588cc996e91d08d89a",
     "grade": false,
     "grade_id": "cell-732533d28be0d7f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q15**: Do the results obtained depend on the set of images used to generate the vocabulary? How can we improve the retrieval performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61429d22",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "579ffa1118fbc2f4afcf2e41cfed997e",
     "grade": false,
     "grade_id": "cell-d18ed77c92a81b75",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6465cfb0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19391fa0b37d795714ed3302f0847a36",
     "grade": false,
     "grade_id": "cell-e611dd64897c293c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q16:** How does TF-IDF affect the performance? Better or worse? Does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b193d85",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee1bf086bcde24459725d8df028eed97",
     "grade": false,
     "grade_id": "cell-00341a8c321999b8",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3b83bc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6874518beeb5a091fed8581c10ef1011",
     "grade": false,
     "grade_id": "cell-6177cc11a553139d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Submitting your work\n",
    "\n",
    "**Important**: Please make sure that the submitted notebooks have been run and the cell outputs are visible.\n",
    "\n",
    "**Important**: Please make also sure that you have filled the **NAME** and **DNI** variables at the beginning of the notebook, **using the indicated format**.\n",
    "\n",
    "Once you have filled out the necessary code and you are happy with your solution, **save your notebook** and execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0d318",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fb2e4ea279e65bae1d2158cee2833cf",
     "grade": false,
     "grade_id": "cell-10bc3c3e005d0af2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "zip_filename = DNI + '_A2.zip'\n",
    "zf = zipfile.ZipFile(zip_filename, mode = 'w')\n",
    "\n",
    "aname = 'submitted/' + DNI + '/A2/Image_Indexing.ipynb'\n",
    "zf.write('Image_Indexing.ipynb', arcname = aname);\n",
    "\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06aa9d3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93bd6809604488b49b428e0cc6fe6a1c",
     "grade": false,
     "grade_id": "cell-74b609759ffc12db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This will generate a zip file of your code called `DNI_A2.zip` in the same directory of the assignment. This is the file that you must upload to [Aula Digital](https://ad.uib.es/) to submit your work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc2805",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3e5f552b4935747a0f94ab360623ea5",
     "grade": false,
     "grade_id": "cell_foot_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "&copy; Emilio Garcia-Fidalgo, University of the Balearic Islands"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
